{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980975e-4c67-40c3-873a-5b3738d7302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import main libraries\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd6ed66-f982-49b9-8e06-7ac5c3d16844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load api key from .env\n",
    "_=load_dotenv()\n",
    "api_key = os.environ['api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c675aaa3-2ac7-4d80-a1c9-296f01ba285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the credentials and youtube connection\n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95497e8-b711-40aa-8121-e4c9fbfc8a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to get channel ids\n",
    "def get_channel_ids(youtube, channel_names):\n",
    "    unique_channel_ids = {}  # Dictionary to store channel names and IDs\n",
    "\n",
    "    for channel_name in channel_names:\n",
    "        # Search for the channel using the channel name\n",
    "        search_response = youtube.search().list(\n",
    "            q=channel_name,\n",
    "            part='id',\n",
    "            type='channel',\n",
    "            maxResults=1\n",
    "        ).execute()\n",
    "\n",
    "        # Extract the channel ID from the search results\n",
    "        channel_id = search_response['items'][0]['id']['channelId']\n",
    "        unique_channel_ids[channel_name] = channel_id\n",
    "\n",
    "        time.sleep(5)\n",
    "        \n",
    "    return unique_channel_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f6b598-9069-42a3-ad2c-40e74385db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of channel names\n",
    "\n",
    "channel_names = ['blockchaindailynews', 'brainbrocrypto', 'cryptoMOC',\n",
    "               'GiantCutie-CH', 'grenadetw', 'desmondcrypto', \n",
    "               'cryptoalvin0617', 'mrblocktw', 'BonnieBlockchain',\n",
    "               'skywee97', 'shuqinbtc', 'CakeBaBa',\n",
    "               'Web3TV_0xTrade', 'goldenrichacademy', 'GongYouChai',\n",
    "               'youtubercrypto', 'ajgameficlub', 'alfred.blockfinance',\n",
    "               'xiao_lin_shuo', 'AhJu']\n",
    "\n",
    "# Get the channel IDs\n",
    "unique_channel_ids = get_channel_ids(youtube, channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d867a-128a-45f9-be7b-ccbd3282ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the channel IDs\n",
    "print(unique_channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27fc598-0c35-4edb-81e3-f72f09a5bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(unique_channel_ids.items()), columns=['Channel Name', 'Channel ID'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f6978-92d4-4776-a442-84ecf069eb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ChannelIDs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b7bee-0485-41d2-8059-e40391041236",
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading from csv for testing purpose only ###\n",
    "\n",
    "channel_df = pd.read_csv('ChannelIDs.csv')\n",
    "channel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f56fa-07d7-4f96-aa2a-761c0ce23fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating list from csv for testing purpose only ###\n",
    "unique_channel_ids = channel_df['Channel ID'].tolist()\n",
    "unique_channel_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beeba7d-ac64-4354-9284-e9d1f3c8a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function to extract channel statistics\n",
    "def get_channel_stats(youtube, unique_channel_ids):\n",
    "    all_channel_data = []\n",
    "    for i in range(len(unique_channel_ids)):\n",
    "        request = youtube.channels().list(\n",
    "            part = 'snippet, contentDetails, statistics',\n",
    "            id = unique_channel_ids)\n",
    "        response = request.execute()\n",
    "\n",
    "        for i in range(len(response['items'])):\n",
    "            channel_data = dict(Channel_name = response['items'][i]['snippet']['title'], \n",
    "                            Channel_playlist =  response['items'][i]['contentDetails']['relatedPlaylists']['uploads'],\n",
    "                            Subscriber_count = response['items'][i]['statistics']['subscriberCount'],\n",
    "                            Video_count = response['items'][i]['statistics']['videoCount'])\n",
    "            all_channel_data.append(channel_data)\n",
    "            \n",
    "        return (all_channel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe2fa69-21db-43ff-859c-6d8d73c13c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_database= get_channel_stats(youtube, unique_channel_ids)\n",
    "channel_database_df = pd.DataFrame(channel_database)\n",
    "channel_database_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b3dd8-97b7-48f9-82f9-40450927b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_database_df.to_csv('Channel_database',sep='\\t', index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eefb58b-af20-4044-852b-c8b907f7310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting playlist containing the entire video_ids of all channels\n",
    "channel_playlists = list(channel_database_df['Channel_playlist'])\n",
    "channel_playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c603ceb-5f43-457d-b7c5-849afcef8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_database_df.to_csv('Channel_database',sep='\\t', index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb86e7-e395-4304-9a9a-596d93683ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function to extract all the videos from the channels\n",
    "def get_all_videos(playlists):\n",
    "    all_video_ids= []\n",
    "    for playlist_id in playlists:\n",
    "        playlist_videos = []\n",
    "        next_page_token = None\n",
    "\n",
    "        while True:\n",
    "            request = youtube.playlistItems().list(\n",
    "                part = 'contentDetails',\n",
    "                playlistId = playlist_id,\n",
    "                maxResults = 50,\n",
    "                pageToken=next_page_token\n",
    "            )                \n",
    "            response = request.execute()\n",
    "\n",
    "            for i in range(len(response['items'])):\n",
    "                video_id = response['items'][i]['contentDetails']['videoId']\n",
    "                playlist_videos.append(video_id)\n",
    "                    \n",
    "            next_page_token = response.get('nextPageToken')               \n",
    "            if not next_page_token:\n",
    "                 break  \n",
    "\n",
    "        all_video_ids.append(playlist_videos)\n",
    "    return all_video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc487115-043a-45bc-8458-c9dc3e9505a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_list= list(get_all_videos(channel_playlists))\n",
    "video_database = list(np.concatenate(video_list))\n",
    "video_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1314c9f1-799f-4a71-a61e-b3e6c6be37c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_database_df = pd.Series(video_list)\n",
    "video_database_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02af96a-1fc9-4e88-ba21-a035825ed1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_database_df.to_csv('Video_database',sep='\\t', index=True,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03fbb37-8535-4cfc-8ab3-75f8e1f87e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function to extract video data from video ids\n",
    "def get_video_details(youtube,videos):\n",
    "    video_details = []\n",
    "    for items in videos:\n",
    "        page_token = None\n",
    "\n",
    "        while True:\n",
    "            request = youtube.videos().list(\n",
    "                part = 'snippet, contentDetails, statistics',\n",
    "                id = items,\n",
    "                maxResults = 50,\n",
    "                pageToken = page_token\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            video_details.extend(response['items'])\n",
    "            page_token = response.get('nextPageToken')\n",
    "\n",
    "            if not page_token:\n",
    "                break\n",
    "\n",
    "        all_details = {\n",
    "            'descriptions': [],\n",
    "            'titles': [],\n",
    "            'view_counts': [],\n",
    "            'channel_ids': [],\n",
    "            'publish_dates': [],\n",
    "            'tags': [],\n",
    "            'thumbnails': []\n",
    "        }\n",
    "    \n",
    "        for video in video_details:\n",
    "            video_id = video['id']\n",
    "            snippet = video['snippet']\n",
    "            statistics = video['statistics']\n",
    "\n",
    "            description = snippet.get('description', '')\n",
    "            title = snippet.get('title', '')\n",
    "            view_count = statistics.get('viewCount', '')\n",
    "        #like_count = statistics.get('likeCount', '')\n",
    "        #dislike_count = statistics.get('dislikeCount', '')\n",
    "            channel_id = snippet.get('channelId', '')\n",
    "            publish_date = snippet.get('publishedAt', '')\n",
    "            tag = snippet.get('tags','')\n",
    "            thumbnail = snippet['thumbnails'].get('default', '')\n",
    "\n",
    "            all_details['descriptions'].append(description)\n",
    "            all_details['titles'].append(title)\n",
    "            all_details['view_counts'].append(view_count)\n",
    "            all_details['channel_ids'].append(channel_id)\n",
    "            all_details['publish_dates'].append(publish_date)\n",
    "            all_details['tags'].append(tag)\n",
    "            all_details['thumbnails'].append(thumbnail)\n",
    "\n",
    "    return all_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79762eae-1b7e-45f6-9ab0-399ac0056f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_video_details(youtube,video_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a46d6ef-30d7-4122-8512-8a1ed6ee7423",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data = get_video_details(youtube,video_database)\n",
    "video_data_df = pd.DataFrame(video_data)\n",
    "video_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2668b2-de00-42c9-a237-e355f02890a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data from CSV for testing purpose only###\n",
    "\n",
    "data_df = pd.read_csv('video_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6789bf84-7ec6-44d2-9a49-03b4c5646377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import translate libraries\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0bdf4-7476-48a8-8b1c-50624d8da746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a translate function\n",
    "\n",
    "def translate(text):\n",
    "    time.sleep(1)\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, src='zh-TW', dest='en')\n",
    "    return translation.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e118f7-93fa-4068-8ea9-de1b86014db1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f0edb0-ce4c-4580-bc07-6a1755a11d66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#testing on all df columns \n",
    "columns_to_translate = ['tags', 'descriptions','titles']\n",
    "start_time = time.time() \n",
    "for column in columns_to_translate:\n",
    "    data_df[f'translated {column}'] = data_df[column].apply(translate)\n",
    "\n",
    "end_time = time.time() \n",
    "total_time = end_time - start_time \n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71caec3-6ff3-4510-b2d7-05e26486c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since it took too long, try on a smaller copy\n",
    "df2=data_df.head(20).copy()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91940f8-8534-4fac-a7a6-36ef392c5f08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test on df2\n",
    "columns_to_translate = ['tags', 'descriptions','titles']\n",
    "start_time = time.time() \n",
    "\n",
    "for column in columns_to_translate:\n",
    "    df2[f'translated {column}'] = df2[column].apply(translate)\n",
    "\n",
    "end_time = time.time() \n",
    "total_time = end_time - start_time \n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1afdd9f-9d3d-4774-be0d-75f93c0a5686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time for translating 20 entries\n",
    "print(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd81ea-12f8-446c-b6d6-e79b831edc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total size of DF\n",
    "len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6be95e-5ed6-41aa-b03f-d6352363d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#theortical total time for translation. \n",
    "88*7085/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d674c4-6d31-4888-a03b-a3e8effc538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying a batch\n",
    "\n",
    "columns_to_translate = ['tags', 'descriptions','titles']\n",
    "\n",
    "#translate a batch of text\n",
    "def translate_batch(batch):\n",
    "    return batch.map(translate)\n",
    "\n",
    "batch_size = 100\n",
    "total_rows = len(df)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#terate in batches\n",
    "for i in range(0, total_rows, batch_size):\n",
    "    batch = df.loc[i:i+batch_size-1, columns_to_translate]\n",
    "    \n",
    "#translate the batch\n",
    "    translated_batch = translate_batch(batch)\n",
    "    \n",
    "#put values back in df\n",
    "    for column in columns_to_translate:\n",
    "        translated_column = f'translated {column}'\n",
    "        df.loc[i:i+batch_size-1, translated_column] = translated_batch[column]\n",
    "    \n",
    "#sleep break    \n",
    "    time.sleep(1)  \n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "\n",
    "    \n",
    "# Display the resulting DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a9e32-abcf-4c07-a06e-6efc6f0941d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e205f-9540-4873-8912-17b264a44c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69167cd-d407-4a5c-9851-3c45c6e9581e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b66c62e-fe4b-494d-9041-9bb4a433e3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199fd680-30c7-4473-a205-4fc617c854db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf5da08-9c4b-4dbd-a938-79edbf51af8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369851f1-6f4e-485a-a3f6-38c574c1debb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fd2af4-04f3-4d57-880c-615c423f2db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
